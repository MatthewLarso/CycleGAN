{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7IotTyJknHV"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH6GTVN74Qt_",
        "outputId": "8d03d32c-d676-474b-a3fe-1a8198f6a05d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "K6pGPAhUcBwK"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils import data\n",
        "from collections import OrderedDict\n",
        "from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import random\n",
        "from torch.autograd import Variable\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbjToCJ0c2MC"
      },
      "source": [
        "# Paramters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n1FdEpC5dTzi"
      },
      "outputs": [],
      "source": [
        "epochs = 100 \n",
        "num_pairs = 200\n",
        "num_residual_blocks = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaFUoaf-dUAz"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "dGCF_7TDeKa-"
      },
      "outputs": [],
      "source": [
        "def conv_block(in_channel, out_channel, activation='relu', *args, **kwargs):\n",
        "    activations = nn.ModuleDict([['lrelu', nn.LeakyReLU(negative_slope=0.2, inplace=True)], ['relu', nn.ReLU()]])\n",
        "    return nn.Sequential(nn.Conv2d(in_channel, out_channel, *args, **kwargs), nn.BatchNorm2d(out_channel), activations[activation])\n",
        "    \n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride =stride,padding =1,bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, in_channels, kernel_size = 3, stride =stride,padding =1,bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "def print_images(iml, dir, epoch, save_mode_on=True):\n",
        "    titles = ['Real-A', 'Fake-B (A->B)', 'Recon-A (A->B->A)', 'Identity-A (A->A)', 'Real-B', 'Fake-A (B->A)', 'Recon-B (B->A->B)', 'Identity-B (B->B)']\n",
        "    idx = 0\n",
        "    fig, arr = plt.subplots(2,4, figsize=(12, 6))\n",
        "    for i in range(2):\n",
        "        for j in range(4):\n",
        "            im = iml[idx].squeeze().T\n",
        "            im = (im + 1) / 2.0\n",
        "            arr[i, j].axis('off')\n",
        "            arr[i, j].imshow(im.detach().cpu(), vmin=0, vmax=1)\n",
        "            arr[i, j].set_title(titles[idx], fontweight=\"bold\")\n",
        "            idx = idx + 1\n",
        "    fig.tight_layout()\n",
        "\n",
        "    if save_mode_on:\n",
        "        plt.savefig(os.path.join(dir, 'epoch-{}.jpg'.format(epoch)))\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "def assign_model_id(modeldir):\n",
        "    return 'ep_' + str(epochs) + '-pairs_' + str(num_pairs) + '-resblocks_' + str(num_residual_blocks)\n",
        "\n",
        "def to_var(x):\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return Variable(x)\n",
        "\n",
        "class ImagePool():\n",
        "    def __init__(self, pool_size):\n",
        "        self.pool_size = pool_size\n",
        "        if self.pool_size > 0:  \n",
        "            self.num_imgs = 0\n",
        "            self.images = []\n",
        "    def query(self, images):\n",
        "        if self.pool_size == 0:  \n",
        "            return images\n",
        "        return_images = []\n",
        "        for image in images:\n",
        "            image = torch.unsqueeze(image.data, 0)\n",
        "            if self.num_imgs < self.pool_size:  \n",
        "                self.num_imgs = self.num_imgs + 1\n",
        "                self.images.append(image)\n",
        "                return_images.append(image)\n",
        "            else:\n",
        "                p = random.uniform(0, 1)\n",
        "                if p > 0.5:  \n",
        "                    random_id = random.randint(0, self.pool_size - 1)  \n",
        "                    tmp = self.images[random_id].clone()\n",
        "                    self.images[random_id] = image\n",
        "                    return_images.append(tmp)\n",
        "                else:       \n",
        "                    return_images.append(image)\n",
        "        return_images = torch.cat(return_images, 0)  \n",
        "        return return_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZ8-kSU8xzaF",
        "outputId": "5ed101bd-871a-4eed-ba79-0a8b2a2b5099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OkEpnKe7Q-c",
        "outputId": "448ab2cf-8358-4be9-96cf-6f2e38155379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5njpuslgYKG"
      },
      "source": [
        "# Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n-cPiCkUgYSZ"
      },
      "outputs": [],
      "source": [
        "def create_generator():\n",
        "    model = nn.Sequential(OrderedDict([]))\n",
        "\n",
        "    encoder = nn.Sequential(OrderedDict([\n",
        "        ('conv1', nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(7,7), stride=1, bias=False, padding=3)),\n",
        "        ('bnorm1', nn.BatchNorm2d(num_features=64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
        "        ('relu1', nn.ReLU()),\n",
        "        ('conv2', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=2, bias=False, padding=1)),\n",
        "        ('bnorm2', nn.BatchNorm2d(num_features=128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
        "        ('relu2', nn.ReLU()),\n",
        "        ('conv3', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), stride=2, bias=False, padding=1)),\n",
        "        ('bnorm3', nn.BatchNorm2d(num_features=256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
        "        ('relu3', nn.ReLU())]))\n",
        "    model.add_module(name='encoder', module=encoder)\n",
        "\n",
        "    for i in range(num_residual_blocks):\n",
        "        model.add_module(name='res{}'.format(i+1), module=ResidualBlock(256,256))\n",
        "\n",
        "    decoder = nn.Sequential(OrderedDict([\n",
        "        ('deconv1', nn.ConvTranspose2d(256,64, kernel_size=(3,3), stride=2, padding=1, output_padding=1)),\n",
        "        ('bnorm4', nn.BatchNorm2d(num_features=64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
        "        ('relu4', nn.ReLU()),\n",
        "        ('deconv2', nn.ConvTranspose2d(64,32, kernel_size=(3,3), stride=2, padding=1, output_padding=1)),\n",
        "        ('bnorm5', nn.BatchNorm2d(num_features=32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
        "        ('relu5', nn.ReLU()),\n",
        "        ('reflectpad', nn.ReflectionPad2d(3)),\n",
        "        ('conv4', nn.Conv2d(in_channels=32, out_channels=3, kernel_size=(7,7), stride=1, bias=True)),\n",
        "        ('tanh', nn.Tanh())]))\n",
        "    model.add_module(name='decoder', module=decoder)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI7XfByMhDSx"
      },
      "source": [
        "# Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LshlLLVIhDZC"
      },
      "outputs": [],
      "source": [
        "def gan_loss(p, real):\n",
        "    if real:\n",
        "        return F.mse_loss(p, torch.ones(p.shape).to(device))\n",
        "    else:\n",
        "        return F.mse_loss(p, torch.zeros(p.shape).to(device))\n",
        "\n",
        "def cycle_loss(reconstructed, real):\n",
        "    return F.l1_loss(reconstructed, real)\n",
        "\n",
        "def identity_loss(identity, real):\n",
        "    return F.l1_loss(identity, real)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtoKyvQEhTGu"
      },
      "source": [
        "# Discriminator:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0ZHvpOWDhTOW"
      },
      "outputs": [],
      "source": [
        "def create_discriminator():\n",
        "    discriminator = nn.Sequential(OrderedDict([\n",
        "        ('conv', nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(4,4), stride=2, padding=1)),\n",
        "        ('lrelu1', nn.LeakyReLU(0.2, True)),\n",
        "        ('convblock1', conv_block(in_channel=64, out_channel=128, activation='lrelu', kernel_size=(4,4), stride=2, padding=1, bias=False)),\n",
        "        ('convblock2', conv_block(in_channel=128, out_channel=256, activation='lrelu', kernel_size=(4,4), stride=2, padding=1, bias=False)),\n",
        "        ('convblock3', conv_block(in_channel=256, out_channel=512, activation='lrelu', kernel_size=(4,4), stride=1, padding=1, bias=False)),\n",
        "        ('patch', nn.Conv2d(in_channels=512, out_channels=1, kernel_size=(4,4), stride=1, padding=1))]))  \n",
        "    return discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-JACN6Oht1O"
      },
      "source": [
        "# GAN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "LI9VRhm_hv6w"
      },
      "outputs": [],
      "source": [
        "class cycleGAN(nn.Module):\n",
        "    def __init__(self, learning_rate=2e-4):\n",
        "        nn.Module.__init__(self)\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.LAMBDA_CYCLE = 10.0\n",
        "        self.LAMBDA_ID = 0.5\n",
        "        pool = 50\n",
        "\n",
        "        self.is_training = True\n",
        "        self.save_losses = False\n",
        "\n",
        "        self.fake_A_pool = ImagePool(pool)\n",
        "        self.fake_B_pool = ImagePool(pool)\n",
        "\n",
        "        self.tr_gen_loss_dict = {\n",
        "            'a2b': [],\n",
        "            'b2a': [],\n",
        "            'id_a2b': [],\n",
        "            'id_b2a': [],\n",
        "            'a2b2a': [],\n",
        "            'b2a2b': [],\n",
        "            'loss_gen_total': []\n",
        "        }\n",
        "        self.tr_dis_loss_dict = {\n",
        "            'loss_dis_b': [],\n",
        "            'loss_dis_a': [],\n",
        "            'loss_dis_total': []\n",
        "        }\n",
        "        self.val_gen_loss_dict = {\n",
        "            'a2b': [],\n",
        "            'b2a': [],\n",
        "            'id_a2b': [],\n",
        "            'id_b2a': [],\n",
        "            'a2b2a': [],\n",
        "            'b2a2b': [],\n",
        "            'loss_gen_total': []\n",
        "        }\n",
        "        self.val_dis_loss_dict = {\n",
        "            'loss_dis_b': [],\n",
        "            'loss_dis_a': [],\n",
        "            'loss_dis_total': []\n",
        "        }\n",
        "\n",
        "        self.im_list = []\n",
        "\n",
        "        self.generator_a2b = create_generator()\n",
        "        self.generator_b2a = create_generator()\n",
        "\n",
        "        self.disc_a = create_discriminator()\n",
        "        self.disc_b = create_discriminator()\n",
        "\n",
        "        self.opt_G = torch.optim.Adam(itertools.chain(self.generator_a2b.parameters(), self.generator_b2a.parameters()), lr=self.learning_rate)\n",
        "        self.opt_D = torch.optim.Adam(itertools.chain(self.disc_a.parameters(), self.disc_b.parameters()), lr=self.learning_rate)\n",
        "\n",
        "    def forward(self, real_a, real_b):\n",
        "        fake_a2b = self.generator_a2b(real_a)\n",
        "        recon_b2a = self.generator_b2a(fake_a2b)\n",
        "        fake_b2a = self.generator_b2a(real_b)\n",
        "        recon_a2b = self.generator_a2b(fake_b2a)\n",
        "        identity_a2b = self.generator_a2b(real_b)\n",
        "        identity_b2a = self.generator_b2a(real_a)\n",
        "        self.im_list = [real_a, fake_a2b, recon_b2a, identity_b2a, real_b, fake_b2a, recon_a2b, identity_a2b]\n",
        "\n",
        "        return fake_a2b, recon_b2a, fake_b2a, recon_a2b, identity_a2b, identity_b2a\n",
        "\n",
        "    def backward_G(self, real_a, real_b, fake_a2b, recon_b2a, fake_b2a, recon_a2b, identity_a2b, identity_b2a):\n",
        "        if self.is_training:\n",
        "            self.set_requires_grad([self.disc_a, self.disc_b], False)\n",
        "            self.opt_G.zero_grad()\n",
        "\n",
        "        loss_identity_a2b = identity_loss(identity_a2b, real_b)\n",
        "        loss_identity_b2a = identity_loss(identity_b2a, real_a)\n",
        "\n",
        "        loss_gan_gen_a2b = gan_loss(self.disc_b(fake_a2b), True)\n",
        "        loss_gan_gen_b2a = gan_loss(self.disc_a(fake_b2a), True)\n",
        "        a2b2a = cycle_loss(recon_b2a, real_a)\n",
        "        b2a2b = cycle_loss(recon_a2b, real_b)\n",
        "\n",
        "        loss_gen_total = loss_gan_gen_a2b + loss_gan_gen_b2a \\\n",
        "            + (a2b2a + b2a2b) * self.LAMBDA_CYCLE \\\n",
        "            + (loss_identity_a2b + loss_identity_b2a) * self.LAMBDA_ID\n",
        "\n",
        "        if self.is_training:\n",
        "            loss_gen_total.backward()\n",
        "            self.opt_G.step()\n",
        "\n",
        "        if self.save_losses:\n",
        "            if self.is_training:\n",
        "                self.tr_gen_loss_dict['a2b'].append(loss_gan_gen_a2b.item())\n",
        "                self.tr_gen_loss_dict['b2a'].append(loss_gan_gen_b2a.item())\n",
        "                self.tr_gen_loss_dict['id_a2b'].append(loss_identity_a2b.item())\n",
        "                self.tr_gen_loss_dict['id_b2a'].append(loss_identity_b2a.item())\n",
        "                self.tr_gen_loss_dict['a2b2a'].append(a2b2a.item())\n",
        "                self.tr_gen_loss_dict['b2a2b'].append(b2a2b.item())\n",
        "                self.tr_gen_loss_dict['loss_gen_total'].append(loss_gen_total.item())\n",
        "            else:\n",
        "                self.val_gen_loss_dict['a2b'].append(loss_gan_gen_a2b.item())\n",
        "                self.val_gen_loss_dict['b2a'].append(loss_gan_gen_b2a.item())\n",
        "                self.val_gen_loss_dict['id_a2b'].append(loss_identity_a2b.item())\n",
        "                self.val_gen_loss_dict['id_b2a'].append(loss_identity_b2a.item())\n",
        "                self.val_gen_loss_dict['a2b2a'].append(a2b2a.item())\n",
        "                self.val_gen_loss_dict['b2a2b'].append(b2a2b.item())\n",
        "                self.val_gen_loss_dict['loss_gen_total'].append(loss_gen_total.item())\n",
        "\n",
        "\n",
        "    def backward_D(self, real_a, real_b, fake_a2b, fake_b2a):\n",
        "        fake_a2b = self.fake_B_pool.query(fake_a2b)\n",
        "        fake_b2a = self.fake_A_pool.query(fake_b2a)\n",
        "\n",
        "        if self.is_training:\n",
        "            self.set_requires_grad([self.disc_a, self.disc_b], True)\n",
        "            self.opt_D.zero_grad()   \n",
        "\n",
        "        loss_gan_dis_a_real = gan_loss(self.disc_a(real_a), True)\n",
        "        loss_gan_dis_a_fake = gan_loss(self.disc_a(fake_b2a.detach()), False)\n",
        "\n",
        "        loss_gan_dis_b_real = gan_loss(self.disc_b(real_b), True)\n",
        "        loss_gan_dis_b_fake = gan_loss(self.disc_b(fake_a2b.detach()), False) \n",
        "\n",
        "        loss_dis_a = (loss_gan_dis_a_real + loss_gan_dis_a_fake) * 0.5\n",
        "        loss_dis_b = (loss_gan_dis_b_real + loss_gan_dis_b_fake) * 0.5\n",
        "\n",
        "        loss_dis_total = loss_dis_a + loss_dis_b\n",
        "\n",
        "        if self.is_training:\n",
        "            loss_dis_total.backward()\n",
        "            self.opt_D.step()\n",
        "\n",
        "        if self.save_losses:\n",
        "            if self.is_training:\n",
        "                self.tr_dis_loss_dict['loss_dis_b'].append(loss_dis_b.item())\n",
        "                self.tr_dis_loss_dict['loss_dis_a'].append(loss_dis_a.item())\n",
        "                self.tr_dis_loss_dict['loss_dis_total'].append(loss_dis_total.item())\n",
        "            else:\n",
        "                self.val_dis_loss_dict['loss_dis_b'].append(loss_dis_b.item())\n",
        "                self.val_dis_loss_dict['loss_dis_a'].append(loss_dis_a.item())\n",
        "                self.val_dis_loss_dict['loss_dis_total'].append(loss_dis_total.item())\n",
        "\n",
        "    def set_requires_grad(self, nets, requires_grad=False):\n",
        "        if not isinstance(nets, list):\n",
        "            nets = [nets]\n",
        "        for net in nets:\n",
        "            if net is not None:\n",
        "                for param in net.parameters():\n",
        "                    param.requires_grad = requires_grad\n",
        "\n",
        "    def optimize_parameters(self, real_a, real_b):\n",
        "        fake_a2b, recon_b2a, fake_b2a, recon_a2b, identity_a2b, identity_b2a = self.forward(real_a, real_b)  \n",
        "        self.backward_G(real_a, real_b, fake_a2b, recon_b2a, fake_b2a, recon_a2b, identity_a2b, identity_b2a)\n",
        "        self.backward_D(real_a, real_b, fake_a2b, fake_b2a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbNCG74zrK8l"
      },
      "source": [
        "# Directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jiKkqopDrMIm"
      },
      "outputs": [],
      "source": [
        "def manage_folders():\n",
        "    timee = datetime.datetime.now().strftime(\"%Y_%m_%d-%H:%M\")\n",
        "\n",
        "    cur = os.getcwd()\n",
        "\n",
        "    if not os.path.isdir(os.path.join(cur, 'Output')):\n",
        "        os.mkdir(os.path.join(cur, 'Output'))\n",
        "\n",
        "    out = os.path.join(cur, 'Output')\n",
        "    out = os.path.join(out, timee)\n",
        "    os.mkdir(out)\n",
        "\n",
        "    graphdir = os.path.join(out, 'loss-graphs')\n",
        "    if not os.path.isdir(graphdir):\n",
        "        os.mkdir(graphdir)\n",
        "\n",
        "    imdir = os.path.join(out, 'generated-images')\n",
        "    if not os.path.isdir(imdir):\n",
        "        os.mkdir(imdir)\n",
        "\n",
        "    trdir = os.path.join(imdir, 'train')\n",
        "    if not os.path.isdir(trdir):\n",
        "        os.mkdir(trdir)\n",
        "\n",
        "    valdir = os.path.join(imdir, 'val')\n",
        "    if not os.path.isdir(valdir):\n",
        "        os.mkdir(valdir)\n",
        "\n",
        "    modeldir = os.path.join(out, 'saved-models')\n",
        "    if not os.path.isdir(modeldir):\n",
        "        os.mkdir(modeldir)\n",
        "\n",
        "    return trdir, valdir, graphdir, modeldir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGzo6W3znl12"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kTBsGjJmit8z"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def pic_loader(pic_type):\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    data_dir = '/content/drive/MyDrive/selfie2anime'\n",
        "\n",
        "    train_path = os.path.join(data_dir, 'train{}'.format(pic_type))\n",
        "    test_path = os.path.join(data_dir, 'test{}'.format(pic_type))\n",
        "\n",
        "    train_dataset = datasets.ImageFolder(train_path, transform)\n",
        "    test_dataset = datasets.ImageFolder(test_path, transform)\n",
        "\n",
        "    train_dloader = DataLoader(dataset=train_dataset, batch_size=1, shuffle=True, num_workers=2)\n",
        "    test_dloader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "    return train_dloader, test_dloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LERaDJy6nmD8"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/MyDrive/selfie2anime'\n",
        "\n",
        "dataloader_A, test_dataloader_A = pic_loader('A')\n",
        "dataloader_B, test_dataloader_B = pic_loader('B')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBXCkZqmhwFg"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Vxx9V7imhwM5"
      },
      "outputs": [],
      "source": [
        "def train(train_dataset_SS, validation_dataset_SS, train_dataset_AA, validation_dataset_AA, epochs, device):\n",
        "\n",
        "    # X_s: Real selfie \n",
        "    # X_a: Real anime \n",
        "    # y_s: Selfie label = 1\n",
        "    # y_a: Anime label = 0\n",
        "\n",
        "    model = cycleGAN().to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_dataset_S = iter(train_dataset_SS)\n",
        "        validation_dataset_S = iter(validation_dataset_SS)\n",
        "        train_dataset_A = iter(train_dataset_AA)\n",
        "        validation_dataset_A = iter(validation_dataset_AA)\n",
        "\n",
        "        print('Epoch', epoch+1, '------------------')\n",
        "\n",
        "        # Training\n",
        "        temp = 1\n",
        "        model.is_training = True\n",
        "        for X_s, y_s in train_dataset_S:\n",
        "            X_a, y_a = train_dataset_A.next()\n",
        "\n",
        "            X_s, y_s = to_var(X_s), to_var(y_s).long().squeeze()\n",
        "            X_a, y_a = to_var(X_a), to_var(y_a).long().squeeze()\n",
        "\n",
        "            X_s, X_a = X_s.to(device), X_a.to(device)\n",
        "\n",
        "            if temp == train_dataset_S.__len__():\n",
        "                model.save_losses = True\n",
        "\n",
        "            model.optimize_parameters(X_s, X_a)\n",
        "\n",
        "            temp = temp+1\n",
        "\n",
        "        print('Tr - Generator Loss:', np.round(model.tr_gen_loss_dict['loss_gen_total'][-1], decimals=4))\n",
        "        print('Tr - Dicriminator Loss:', np.round(model.tr_dis_loss_dict['loss_dis_total'][-1], decimals=4))\n",
        "\n",
        "        model.save_losses = False\n",
        "        print_images(model.im_list, trdir, str(epoch), save_mode_on=True)\n",
        "\n",
        "        # Validation\n",
        "        with torch.set_grad_enabled(False):\n",
        "            temp = 1\n",
        "            model.is_training = False\n",
        "            for X_s, y_s in validation_dataset_S:\n",
        "                X_a, y_a = validation_dataset_A.next()\n",
        "                X_s, y_s = to_var(X_s), to_var(y_s).long().squeeze()\n",
        "                X_a, y_a = to_var(X_a), to_var(y_a).long().squeeze()\n",
        "\n",
        "                X_s, X_a = X_s.to(device), X_a.to(device)\n",
        "\n",
        "                if temp == validation_dataset_S.__len__():\n",
        "                    model.save_losses = True\n",
        "\n",
        "                model.optimize_parameters(X_s, X_a)\n",
        "\n",
        "                temp = temp+1\n",
        "\n",
        "            print('Val - Generator Loss:', np.round(model.val_gen_loss_dict['loss_gen_total'][-1], decimals=4))\n",
        "            print('Val - Dicriminator Loss:', np.round(model.val_dis_loss_dict['loss_dis_total'][-1], decimals=4))\n",
        "\n",
        "            model.save_losses = False\n",
        "            print_images(model.im_list, valdir, str(epoch), save_mode_on=True)\n",
        "\n",
        "    #save everthing\n",
        "    df = pd.DataFrame.from_dict(model.tr_gen_loss_dict)\n",
        "    df.to_csv(os.path.join(graphdir, 'tr_gen_losses.csv'), index=False)\n",
        "    df = pd.DataFrame.from_dict(model.tr_dis_loss_dict)\n",
        "    df.to_csv(os.path.join(graphdir, 'tr_dis_losses.csv'), index=False)\n",
        "    df = pd.DataFrame.from_dict(model.val_gen_loss_dict)\n",
        "    df.to_csv(os.path.join(graphdir, 'val_gen_losses.csv'), index=False)\n",
        "    df = pd.DataFrame.from_dict(model.val_dis_loss_dict)\n",
        "    df.to_csv(os.path.join(graphdir, 'val_dis_losses.csv'), index=False)\n",
        "    torch.save(model.state_dict(), os.path.join(modeldir, assign_model_id(modeldir)) + '.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te32IbSiikTS"
      },
      "source": [
        "Run training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "jz3tNjGJikh_",
        "outputId": "e94841a5-1de7-4c4d-b802-9c92cc49c0ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 ------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-2dc6a93901cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvaldir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodeldir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanage_folders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataloader_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-935bdfe1b73f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dataset_SS, validation_dataset_SS, train_dataset_AA, validation_dataset_AA, epochs, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-3be2cc94527e>\u001b[0m in \u001b[0;36moptimize_parameters\u001b[0;34m(self, real_a, real_b)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mfake_a2b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_b2a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_b2a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_a2b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentity_a2b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentity_b2a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_a2b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_b2a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_b2a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_a2b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentity_a2b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentity_b2a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_a2b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_b2a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-3be2cc94527e>\u001b[0m in \u001b[0;36mbackward_G\u001b[0;34m(self, real_a, real_b, fake_a2b, recon_b2a, fake_b2a, recon_a2b, identity_a2b, identity_b2a)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mloss_gen_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trdir, valdir, graphdir, modeldir = manage_folders()\n",
        "train((dataloader_A), (test_dataloader_A), (dataloader_B), (test_dataloader_B), epochs, device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "final_proj.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}